{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e",
   "display_name": "Python 3.7.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2x Single-Image Super-Resolution on Grayscale Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Assignment:** Individual Class Project<br>\n",
    "**Author:** Richard Hemphill<br>\n",
    "**ID:** 903877709<br>\n",
    "**Class:** ECE5268 Theory of Neural Networks<br>\n",
    "**Instructor:** Dr. Georgios C. Anagnostopoulos<br>\n",
    "**Description:** Using small-sized grayscale images, construct a CNN-based architecture that will downscale (magnify) the images by a factor of 2.<br>\n",
    "**Emphasis:** Describe the concept of single-image super-resolution, describe the architecture in sufficient detail and show indicative training and post-training results.<br>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**References:**\n",
    "* https://www.kaggle.com/spaceengineer1/alexonly-greyscale\n",
    "* https://www.kaggle.com/c/two-sigma-financial-news/discussion/83593\n",
    "* https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os.path\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SET_OWNER = 'spaceengineer1'\n",
    "IMAGE_SET_FILE = 'alexonly-greyscale'\n",
    "ZIP_EXTENSION = 'zip'\n",
    "IMAGE_EXTENSION = 'jpg'\n",
    "PROCESSED_IMAGE_FOLDER ='dataSet'\n",
    "TRAIN_FOLDER = 'train'\n",
    "TEST_FOLDER = 'test'\n",
    "RESCALE_FACTOR = 1./255\n",
    "VALIDATION_SPLIT = 0.2\n",
    "CHANNELS = 1\n",
    "ORIG_IMG_SIZE = 64\n",
    "UPSCALE_FACTOR = 2\n",
    "LOW_RES_IMG_SIZE = int(ORIG_IMG_SIZE/UPSCALE_FACTOR)"
   ]
  },
  {
   "source": [
    "## Prepocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raw image set\n",
    "def DownloadImageSet(imageSetOwner = IMAGE_SET_OWNER, imageSetFile = IMAGE_SET_FILE):\n",
    "    zipFile = '{}.{}'.format(imageSetFile, ZIP_EXTENSION)\n",
    "    if not os.path.isfile(zipFile):\n",
    "        # connect to the Kaggle Database and download dataset\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_download_files('{}/{}'.format(imageSetOwner, imageSetFile))\n",
    "    # extract the dataset\n",
    "    zf = ZipFile(zipFile)\n",
    "    topDir = ''.join({item.split('/')[0] for item in zf.namelist()})\n",
    "    if not os.path.isdir(topDir):\n",
    "        zf.extractall() \n",
    "        zf.close()\n",
    "        \n",
    "    return topDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images as needed for training\n",
    "def PreProcessImages(rawFolder, processedFolder=PROCESSED_IMAGE_FOLDER, size=ORIG_IMG_SIZE, extension = IMAGE_EXTENSION):\n",
    "    pathlist = Path(rawFolder).glob('**/*.{}'.format(extension))\n",
    "    for rawImg in pathlist:\n",
    "        newImg = str(rawImg).replace(rawFolder, processedFolder)\n",
    "        if os.path.isfile(newImg):\n",
    "            continue\n",
    "        img = Image.open(rawImg)\n",
    "        resizeImg = img.resize((size,size), resample=Image.ANTIALIAS)\n",
    "        os.makedirs(os.path.dirname(newImg), exist_ok=True)\n",
    "        resizeImg.save(newImg)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Images\n",
    "imgFolder = DownloadImageSet()\n",
    "PreProcessImages(rawFolder=imgFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 644 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "trainSet = ImageDataGenerator(rescale=RESCALE_FACTOR, validation_split=VALIDATION_SPLIT).flow_from_directory(\n",
    "    PROCESSED_IMAGE_FOLDER,\n",
    "    target_size=(LOW_RES_IMG_SIZE, LOW_RES_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training',\n",
    "    classes=[TRAIN_FOLDER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 160 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "valSet = ImageDataGenerator(rescale=RESCALE_FACTOR, validation_split=VALIDATION_SPLIT).flow_from_directory(\n",
    "    PROCESSED_IMAGE_FOLDER,\n",
    "    target_size=(LOW_RES_IMG_SIZE, LOW_RES_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation',\n",
    "    classes=[TRAIN_FOLDER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 269 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "testSet = ImageDataGenerator(rescale=RESCALE_FACTOR).flow_from_directory(\n",
    "    PROCESSED_IMAGE_FOLDER,\n",
    "    target_size=(LOW_RES_IMG_SIZE, LOW_RES_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=[TEST_FOLDER])"
   ]
  },
  {
   "source": [
    "## Create Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperResolution():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=CHANNELS * LOW_RES_IMG_SIZE^2, kernel_size=9, activation='relu', padding='same'))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=1, activation='relu', padding='same'))\n",
    "    model.add(keras.layers.Conv2D(filters=CHANNELS * ORIG_IMG_SIZE^2, kernel_size=5, activation='relu', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = SuperResolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}