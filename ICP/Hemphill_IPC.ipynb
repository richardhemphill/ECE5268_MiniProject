{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e",
   "display_name": "Python 3.7.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2x Single-Image Super-Resolution on Grayscale Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Assignment:** Individual Class Project<br>\n",
    "**Author:** Richard Hemphill<br>\n",
    "**ID:** 903877709<br>\n",
    "**Class:** ECE5268 Theory of Neural Networks<br>\n",
    "**Instructor:** Dr. Georgios C. Anagnostopoulos<br>\n",
    "**Description:** Using small-sized grayscale images, construct a CNN-based architecture that will downscale (magnify) the images by a factor of 2.<br>\n",
    "**Emphasis:** Describe the concept of single-image super-resolution, describe the architecture in sufficient detail and show indicative training and post-training results.<br>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**References:**\n",
    "* https://www.kaggle.com/spaceengineer1/alexonly-greyscale\n",
    "* https://www.kaggle.com/c/two-sigma-financial-news/discussion/83593\n",
    "* https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os.path\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CURRENT_DIRECTORY = '.'\n",
    "RANDRANGE_STOP = 10000\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SET_OWNER = 'spaceengineer1'\n",
    "IMAGE_SET_FILE = 'alexonly-greyscale'\n",
    "ZIP_EXTENSION = 'zip'\n",
    "IMAGE_EXTENSION = 'jpg'\n",
    "PROCESSED_IMAGE_FOLDER ='dataSet'\n",
    "TRAIN_FOLDER = 'train'\n",
    "TEST_FOLDER = 'test'\n",
    "RESCALE_FACTOR = 255.0\n",
    "VALIDATION_SPLIT = 0.2\n",
    "CHANNELS = 1\n",
    "ORIG_IMG_SIZE = 64\n",
    "UPSCALE_FACTOR = 2\n",
    "LOW_RES_IMG_SIZE = int(ORIG_IMG_SIZE/UPSCALE_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 12558562390513073007\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 1469487515\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 12871924548600066255\nphysical_device_desc: \"device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n]\n"
     ]
    }
   ],
   "source": [
    "# Check if Keras is using GPU\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "source": [
    "## Prepocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raw image set\n",
    "def DownloadImageSet(imageSetOwner = IMAGE_SET_OWNER, imageSetFile = IMAGE_SET_FILE):\n",
    "    zipFile = '{}.{}'.format(imageSetFile, ZIP_EXTENSION)\n",
    "    if not os.path.isfile(zipFile):\n",
    "        # connect to the Kaggle Database and download dataset\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_download_files('{}/{}'.format(imageSetOwner, imageSetFile))\n",
    "    # extract the dataset\n",
    "    zf = ZipFile(zipFile)\n",
    "    topDir = ''.join({item.split('/')[0] for item in zf.namelist()})\n",
    "    if not os.path.isdir(topDir):\n",
    "        zf.extractall() \n",
    "        zf.close()\n",
    "\n",
    "    testDirPre = os.path.join(topDir,TEST_FOLDER)\n",
    "    if os.path.isdir(testDirPre):\n",
    "        testDir = shutil.move(testDirPre, CURRENT_DIRECTORY)\n",
    "    else:\n",
    "        testDir = TEST_FOLDER\n",
    "        \n",
    "    return topDir, testDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Images\n",
    "trainFolder, testFolder = DownloadImageSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageNorm(image):\n",
    "    image = image/RESCALE_FACTOR\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shrink(input):\n",
    "    return tf.image.resize(input,[LOW_RES_IMG_SIZE,LOW_RES_IMG_SIZE],method='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1304 files belonging to 1 classes.\nUsing 1044 files for training.\n"
     ]
    }
   ],
   "source": [
    "trainSet = image_dataset_from_directory(\n",
    "    directory=trainFolder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(ORIG_IMG_SIZE,ORIG_IMG_SIZE),\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='training',\n",
    "    color_mode='grayscale',\n",
    "    seed=random.randrange(RANDRANGE_STOP),\n",
    "    label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x20A29853FC8>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "for batch in trainSet.take(1):\n",
    "    display(array_to_img(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = trainSet.map(ImageNorm)\n",
    "trainSet = trainSet.map(lambda x: (Shrink(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1304 files belonging to 1 classes.\nUsing 260 files for validation.\n"
     ]
    }
   ],
   "source": [
    "valSet = image_dataset_from_directory(\n",
    "    directory=trainFolder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(ORIG_IMG_SIZE,ORIG_IMG_SIZE),\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='validation',\n",
    "    color_mode='grayscale',\n",
    "    seed=random.randrange(RANDRANGE_STOP),\n",
    "    label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "valSet = valSet.map(ImageNorm)\n",
    "valSet = valSet.map(lambda x: (Shrink(x),x))"
   ]
  },
  {
   "source": [
    "## Create Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperResolution(upscaleFactor=UPSCALE_FACTOR, channels=CHANNELS):\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=9, activation='relu', kernel_initializer='Orthogonal', padding='same')(inputs)\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=1, activation='relu', kernel_initializer='Orthogonal', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(filters=(channels * (upscaleFactor ** 2)), kernel_size=5, activation='relu', kernel_initializer='Orthogonal', padding='same')(x)\n",
    "    outputs = tf.nn.depth_to_space(x, upscaleFactor)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XingyuLong(upscaleFactor=UPSCALE_FACTOR, channels=CHANNELS):\n",
    "    convArgs = {\n",
    "        'activation': 'relu',\n",
    "        'kernel_initializer': 'Orthogonal',\n",
    "        'padding': 'same'\n",
    "    }\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=5, **convArgs)(inputs)\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=3, **convArgs)(x)\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=3, **convArgs)(x)\n",
    "    x = keras.layers.Conv2D(filters=(channels * (upscaleFactor ** 2)), kernel_size=3, **convArgs)(x)\n",
    "    outputs = tf.nn.depth_to_space(x, upscaleFactor)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, None, None, 1)]   0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, None, None, 64)    1664      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, None, None, 64)    36928     \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, None, None, 32)    18464     \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, None, None, 4)     1156      \n_________________________________________________________________\ntf.nn.depth_to_space_2 (TFOp (None, None, None, 1)     0         \n=================================================================\nTotal params: 58,212\nTrainable params: 58,212\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xl = XingyuLong()\n",
    "xl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, None, None, 1)]   0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, None, None, 64)    5248      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, None, None, 32)    2080      \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, None, None, 4)     3204      \n_________________________________________________________________\ntf.nn.depth_to_space_3 (TFOp (None, None, None, 1)     0         \n=================================================================\nTotal params: 10,532\nTrainable params: 10,532\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sr = SuperResolution()\n",
    "sr.summary()"
   ]
  },
  {
   "source": [
    "## Train the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
    "lossFn = keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/300\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 0.1550 - val_loss: 0.0992\n",
      "Epoch 2/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0923 - val_loss: 0.0839\n",
      "Epoch 3/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 4/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0826 - val_loss: 0.0823\n",
      "Epoch 5/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0824 - val_loss: 0.0817\n",
      "Epoch 6/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0812 - val_loss: 0.0812\n",
      "Epoch 7/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0806 - val_loss: 0.0806\n",
      "Epoch 8/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0801 - val_loss: 0.0800\n",
      "Epoch 9/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0793 - val_loss: 0.0791\n",
      "Epoch 10/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0782 - val_loss: 0.0614\n",
      "Epoch 11/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0503 - val_loss: 0.0359\n",
      "Epoch 12/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0348 - val_loss: 0.0340\n",
      "Epoch 13/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0333 - val_loss: 0.0330\n",
      "Epoch 14/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0328 - val_loss: 0.0322\n",
      "Epoch 15/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0320 - val_loss: 0.0315\n",
      "Epoch 16/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0312 - val_loss: 0.0308\n",
      "Epoch 17/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0305 - val_loss: 0.0301\n",
      "Epoch 18/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0299 - val_loss: 0.0295\n",
      "Epoch 19/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0293 - val_loss: 0.0289\n",
      "Epoch 20/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0285 - val_loss: 0.0284\n",
      "Epoch 21/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0281 - val_loss: 0.0279\n",
      "Epoch 22/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0274 - val_loss: 0.0275\n",
      "Epoch 23/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 24/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0268 - val_loss: 0.0266\n",
      "Epoch 25/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0265 - val_loss: 0.0262\n",
      "Epoch 26/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0260 - val_loss: 0.0258\n",
      "Epoch 27/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0259 - val_loss: 0.0254\n",
      "Epoch 28/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0256 - val_loss: 0.0251\n",
      "Epoch 29/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0247 - val_loss: 0.0247\n",
      "Epoch 30/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 31/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0239 - val_loss: 0.0241\n",
      "Epoch 32/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0239 - val_loss: 0.0238\n",
      "Epoch 33/300\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 34/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 35/300\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 0.0232 - val_loss: 0.0229\n",
      "Epoch 36/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0225 - val_loss: 0.0227\n",
      "Epoch 37/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0225 - val_loss: 0.0224\n",
      "Epoch 38/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0225 - val_loss: 0.0222\n",
      "Epoch 39/300\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 40/300\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 41/300\n",
      " 45/105 [===========>..................] - ETA: 3s - loss: 0.0219"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-03e0a650d7ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlossFn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sr.compile(optimizer=opt, loss=lossFn)\n",
    "sr.fit(trainSet, epochs=EPOCHS, validation_data=valSet, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "105/105 [==============================] - 11s 92ms/step - loss: 0.1718 - val_loss: 0.1390\n",
      "Epoch 2/15\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.1385 - val_loss: 0.1244\n",
      "Epoch 3/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.1270 - val_loss: 0.1218\n",
      "Epoch 4/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.1250 - val_loss: 0.1214\n",
      "Epoch 5/15\n",
      "105/105 [==============================] - 9s 85ms/step - loss: 0.1250 - val_loss: 0.1210\n",
      "Epoch 6/15\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.1247 - val_loss: 0.1204\n",
      "Epoch 7/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.1216 - val_loss: 0.0946\n",
      "Epoch 8/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.0914 - val_loss: 0.0774\n",
      "Epoch 9/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.0785 - val_loss: 0.0740\n",
      "Epoch 10/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.0754 - val_loss: 0.0730\n",
      "Epoch 11/15\n",
      "105/105 [==============================] - 9s 82ms/step - loss: 0.0749 - val_loss: 0.0726\n",
      "Epoch 12/15\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.0746 - val_loss: 0.0721\n",
      "Epoch 13/15\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.0737 - val_loss: 0.0714\n",
      "Epoch 14/15\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.0729 - val_loss: 0.0688\n",
      "Epoch 15/15\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.0578 - val_loss: 0.0303\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a29bb38c8>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "xl.compile(optimizer=opt, loss=lossFn)\n",
    "xl.fit(trainSet, epochs=EPOCHS, validation_data=valSet, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "source": [
    "## Test the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MagnifyImage(model, lowResImg):\n",
    "    lowResArr = img_to_array(lowResImg)\n",
    "    lowResArr = lowResArr.astype('float32')/RESCALE_FACTOR\n",
    "    input = np.expand_dims(lowResArr, axis=0)\n",
    "    out = model.predict(input)\n",
    "    out *= RESCALE_FACTOR\n",
    "    out = out.reshape((ORIG_IMG_SIZE,ORIG_IMG_SIZE,CHANNELS))\n",
    "    out = array_to_img(x=out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testImgPaths = glob.glob('{}/*.{}'.format(testFolder, IMAGE_EXTENSION))\n",
    "for idx, testImgPath in enumerate(testImgPaths):\n",
    "    if idx > 0:\n",
    "        continue\n",
    "    img = load_img(testImgPath, color_mode='grayscale')\n",
    "    hiResImg = img.resize((ORIG_IMG_SIZE,ORIG_IMG_SIZE), resample=PIL.Image.BICUBIC)\n",
    "    lowResImg = hiResImg.resize((LOW_RES_IMG_SIZE,LOW_RES_IMG_SIZE), resample=PIL.Image.BICUBIC)\n",
    "    biCubicImg = lowResImg.resize((ORIG_IMG_SIZE,ORIG_IMG_SIZE), resample=PIL.Image.BICUBIC)\n",
    "    superResImg = MagnifyImage(sr,lowResImg)\n",
    "    xlImg = MagnifyImage(xl,lowResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x20A29894488>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(hiResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=32x32 at 0x20A29BC2B48>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADEUlEQVR4nCXTS24cVRQG4P+ce+6tV3c67diJ4yAgRApCMgwQA0ZM2QH7YgmsgAWwBcRLSoQCliLycty2u6uruqpu3cdhkA18s49+DLNezI8//4acdXYhQP7pr4+9Gomq2r6X/05p0fTtggnMhgCA2SX4GGwo75YiVVxxnjpmw2wZAGnmHJgMSRhJXpXO12ZLzMzWEQDA2HEW7Zfekoh7d/ZPMyIYsHEMAGCdjIsH6aOaN/KpVKs3xQPnyIoBAEDBKXadRB7mS6m6XXm82b5+XrqnH4A0Q/3N3mrO0TXybF/PLtKL/tD8cA4AuLzSfuj3d2LW6aTiNjSnbyk1jPBbBADEyP0mLZfB5FmPeK7D6kHYbYlzeztkAFm1iYVOhZrKrOXmUfmsxnE1Bkpje7pE+P2QfOx8tr0r2yvxB3YvVy0PI3WdIWBzMfImjruTKpJ5UYnrUD3oVjkccNk+rYHLTcfF4Be+W8jUdcLrq/5Epmyinf49o2P4wH6rjcTlvCWycpJoj9UNPzIS/8b3QN8NRZPHjdv205lp5KrTmPojrYcYN3p+inFrNU3XXS2uLAxkfPR2KuqLKsudue1+eTj8WcRXSO4k1hzFBInDmQ+1Wd0OTxKF5z9Xr20fF+X10i/bte6/lNzS+tAvn/h3Jh/G9a/ZWTfvGtt9Mu+m5tuvxBU7OX+4shfVVLrCxbDz5b2Ya35/uf3iu/YPOm1WaytVNXBpUFZiLvq7pCkjHbr5aP+Kvl7cxQVP65N7HpU4VN6HOTLmDAyXfpaP8jQCpw/N1pUzWDllIHsp85Sbz+IsW5B73Nh+XDhvNCJlzWwQYrWMIdhCUtkUJrZpzUGJMidAM2dOe1tXdo5yXHDYjc1RnLRQr8wcY9IcYh7bxR2n4nS4Ge4tp5AIIsgsSpqzQeC8H+tChn6g+/WUFVDK2WqK/R6GG84EP1m5je5+eb3PYAJzUVO/HXIArDFWWLxc19jy1SErzSXUIoYMGzl75US2KmmRiZhzUonESQkKAKoAgcmIkDATMxMRGB9uakqaYko5qf4Pri7VX6ThyFYAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(lowResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x20A2979B7C8>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(biCubicImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x20A29D40C48>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(superResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x20A29DAD548>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(xlImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}