{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e",
   "display_name": "Python 3.7.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2x Single-Image Super-Resolution on Grayscale Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Assignment:** Individual Class Project<br>\n",
    "**Author:** Richard Hemphill<br>\n",
    "**ID:** 903877709<br>\n",
    "**Class:** ECE5268 Theory of Neural Networks<br>\n",
    "**Instructor:** Dr. Georgios C. Anagnostopoulos<br>\n",
    "**Description:** Using small-sized grayscale images, construct a CNN-based architecture that will downscale (magnify) the images by a factor of 2.<br>\n",
    "**Emphasis:** Describe the concept of single-image super-resolution, describe the architecture in sufficient detail and show indicative training and post-training results.<br>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**References:**\n",
    "* https://www.kaggle.com/spaceengineer1/alexonly-greyscale\n",
    "* https://www.kaggle.com/c/two-sigma-financial-news/discussion/83593\n",
    "* https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os.path\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CURRENT_DIRECTORY = '.'\n",
    "TEMP_DIRECTORY = './tmp/'\n",
    "RANDRANGE_STOP = 10000\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SET_OWNER = 'spaceengineer1'\n",
    "IMAGE_SET_FILE = 'alexonly-greyscale'\n",
    "ZIP_EXTENSION = 'zip'\n",
    "IMAGE_EXTENSION = 'jpg'\n",
    "PROCESSED_IMAGE_FOLDER ='dataSet'\n",
    "TRAIN_FOLDER = 'train'\n",
    "TEST_FOLDER = 'test'\n",
    "RESCALE_FACTOR = 255.0\n",
    "VALIDATION_SPLIT = 0.2\n",
    "CHANNELS = 1\n",
    "ORIG_IMG_SIZE = 64\n",
    "UPSCALE_FACTOR = 2\n",
    "LOW_RES_IMG_SIZE = int(ORIG_IMG_SIZE/UPSCALE_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check if Tensorflow is using GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "source": [
    "## Prepocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raw image set\n",
    "def DownloadImageSet(imageSetOwner = IMAGE_SET_OWNER, imageSetFile = IMAGE_SET_FILE):\n",
    "    zipFile = '{}.{}'.format(imageSetFile, ZIP_EXTENSION)\n",
    "    if not os.path.isfile(zipFile):\n",
    "        # connect to the Kaggle Database and download dataset\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_download_files('{}/{}'.format(imageSetOwner, imageSetFile))\n",
    "    # extract the dataset\n",
    "    zf = ZipFile(zipFile)\n",
    "    topDir = ''.join({item.split('/')[0] for item in zf.namelist()})\n",
    "    if not os.path.isdir(topDir):\n",
    "        zf.extractall() \n",
    "        zf.close()\n",
    "\n",
    "    testDirPre = os.path.join(topDir,TEST_FOLDER)\n",
    "    if os.path.isdir(testDirPre):\n",
    "        if not os.path.isdir(TEST_FOLDER):\n",
    "            shutil.move(testDirPre, CURRENT_DIRECTORY)\n",
    "        \n",
    "    return topDir, TEST_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Images\n",
    "trainFolder, testFolder = DownloadImageSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImgPaths = glob.glob('{}/*.{}'.format(testFolder, IMAGE_EXTENSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageNorm(image):\n",
    "    image = image/RESCALE_FACTOR\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shrink(input):\n",
    "    return tf.image.resize(input,[LOW_RES_IMG_SIZE,LOW_RES_IMG_SIZE],method='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 804 files belonging to 1 classes.\n",
      "Using 644 files for training.\n"
     ]
    }
   ],
   "source": [
    "trainSet = image_dataset_from_directory(\n",
    "    directory=trainFolder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(ORIG_IMG_SIZE,ORIG_IMG_SIZE),\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='training',\n",
    "    color_mode='grayscale',\n",
    "    seed=random.randrange(RANDRANGE_STOP),\n",
    "    label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = trainSet.map(ImageNorm)\n",
    "trainSet = trainSet.map(lambda x: (Shrink(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 804 files belonging to 1 classes.\n",
      "Using 160 files for validation.\n"
     ]
    }
   ],
   "source": [
    "valSet = image_dataset_from_directory(\n",
    "    directory=trainFolder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(ORIG_IMG_SIZE,ORIG_IMG_SIZE),\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='validation',\n",
    "    color_mode='grayscale',\n",
    "    seed=random.randrange(RANDRANGE_STOP),\n",
    "    label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "valSet = valSet.map(ImageNorm)\n",
    "valSet = valSet.map(lambda x: (Shrink(x),x))"
   ]
  },
  {
   "source": [
    "## Utility Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MagnifyImage(model, lowResImg):\n",
    "    lowResArr = img_to_array(lowResImg)\n",
    "    lowResArr = lowResArr.astype('float32')/RESCALE_FACTOR\n",
    "    lowResArr = np.expand_dims(lowResArr, axis=0)\n",
    "    hiResArr = model.predict(lowResArr)\n",
    "    hiResArr *= RESCALE_FACTOR\n",
    "    hiResArr = hiResArr.reshape((ORIG_IMG_SIZE,ORIG_IMG_SIZE,CHANNELS))\n",
    "    hiResImg = array_to_img(hiResArr)\n",
    "    return hiResImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperCallback(keras.callbacks.Callback):\n",
    "    # Store PSNR value in each epoch.\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.psnr = []\n",
    "\n",
    "    # Print result of PNSR per Epoch\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Mean PSNR for epoch({}): {:.2f}'.format(epoch,np.mean(self.psnr)))\n",
    "\n",
    "    # Aggregate PNSR per batch run\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.psnr.append(10 * math.log10(1 / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training when there is no change in loss for <patience> Epochs\n",
    "earlyStoppingCallback = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Periodically save the model.\n",
    "modelCheckpointCallback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=TEMP_DIRECTORY,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List set of callbacks to use during training.\n",
    "callbacks = [SuperCallback(), earlyStoppingCallback, modelCheckpointCallback]"
   ]
  },
  {
   "source": [
    "## Create Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperResolution(upscaleFactor=UPSCALE_FACTOR, channels=CHANNELS):\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = keras.layers.Conv2D(filters=64, kernel_size=9, activation='relu', kernel_initializer='Orthogonal', padding='same')(inputs)\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=1, activation='relu', kernel_initializer='Orthogonal', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(filters=(channels * (upscaleFactor ** 2)), kernel_size=5, activation='relu', kernel_initializer='Orthogonal', padding='same')(x)\n",
    "    outputs = tf.nn.depth_to_space(x, upscaleFactor)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_21\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_22 (InputLayer)        [(None, None, None, 1)]   0         \n_________________________________________________________________\nconv2d_63 (Conv2D)           (None, None, None, 64)    5248      \n_________________________________________________________________\nconv2d_64 (Conv2D)           (None, None, None, 32)    2080      \n_________________________________________________________________\nconv2d_65 (Conv2D)           (None, None, None, 4)     3204      \n_________________________________________________________________\ntf.nn.depth_to_space_21 (TFO (None, None, None, 1)     0         \n=================================================================\nTotal params: 10,532\nTrainable params: 10,532\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sr = SuperResolution()\n",
    "sr.summary()"
   ]
  },
  {
   "source": [
    "## Train the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
    "lossFn = keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "65/65 [==============================] - 6s 86ms/step - loss: 0.1299 - val_loss: 0.0855\n",
      "Mean PSNR for epoch(0): 10.56\n",
      "./tmp\\\n",
      "Epoch 2/2\n",
      "65/65 [==============================] - 6s 86ms/step - loss: 0.0822 - val_loss: 0.0742\n",
      "Mean PSNR for epoch(1): 11.30\n",
      "./tmp\\\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16036fafe08>"
      ]
     },
     "metadata": {},
     "execution_count": 576
    }
   ],
   "source": [
    "sr.compile(optimizer=opt, loss=lossFn)\n",
    "sr.fit(trainSet, epochs=EPOCHS, callbacks=callbacks, validation_data=valSet, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "source": [
    "## Test the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000016036FB55E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "for idx, testImgPath in enumerate(testImgPaths):\n",
    "    if idx > 0:\n",
    "        continue\n",
    "    img = load_img(testImgPath, color_mode='grayscale', target_size=(ORIG_IMG_SIZE,ORIG_IMG_SIZE))\n",
    "    lowResImg = img.resize((LOW_RES_IMG_SIZE,LOW_RES_IMG_SIZE), resample=PIL.Image.BICUBIC)\n",
    "    biCubicImg = img.resize((ORIG_IMG_SIZE,ORIG_IMG_SIZE), resample=PIL.Image.BICUBIC)\n",
    "    superResImg = MagnifyImage(sr,lowResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x16036BCF3C8>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=32x32 at 0x16036E042C8>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADJElEQVR4nCXO224bVRQG4H+tvebkGSe2RdIkbWnTVgIESLRIXPQ1ueAxeAJuuCsCKrXQiBS1VUKaYDtxxvYc9uzD4oLvCT76foibC/P59DnSJE3GBhh+OK8kERPUhfZSzvJRXmyuH4KZ2QAAxFQhaYxEW0yFk73svvfvrTCzEQaANN56y3Bq+hvHZ/NuPo4DMxNLRgAU5gjNEGrb+FhKPmQvpPedUcMJAwA4Cotblg0QLuXTjKrbYqYZEvm/AE3Jae/WMZK/kGLVHBY3df0ymKdjAAC5LHHvgySEYcTyZ5NfmIDXH4fdgz0CgDNgsdF6h8wwzCpe0c7DK0pGQv2PHgAw9DfvrobJ1Iam3RxxH7rq2NULTvLhLALAjusrl4chaYq03+XLqZwA47Lrb5PqowL68gLGDduV7zbS/Mp87cJfrna9DbRdBODjqxYxvV62UWx7Mpd0GKpZP1az9knzSICrtovcbMf+/NBorNntL/92LM2a5Pyf5h3gtxzed9NC7sW6o1SObLvu9xaOkwn9fPrVI7j29s7Bm2FRtYvwJGOZr5yftDtFKm5jus+A9VXhVt6uI6dmnDmxd982+eGH6gClCfNfvvYv8vSPlLTKc+ste/H13VU9epBedI9tyh9+St+6BpPidC/OblKaf0mP9vbrZpefxd+y2dwepxpsfZ7ksfkuvmqmD76hp2Usjh+XvDxZ7bbJHe2uNvdt35eZ/bB4/uxiTbPJbLam0W6CXDQbGXnd7gMxQDcb2p+f0rfpHfw+pr3soAs7lGrV28E55j4S+n/7jdyLTVfy5Cgu88yKxN5H0uhk5HvNj+0gK6XsySjdtDupNYmHV0QW8i4fB+fyTFxeZuLrOIUFQSmqKjiw38ooNz7IgbC/tsXMuZjHXtkgWsD74Ju6Gqcqou2y/WTc+gAkhsAUOaiysgmbrkxla9e0X9oQwSwySOCwXTFJwaq+t0ZuBzkslnUAm8x4N0V7awfHMFkSJadAX4xMJpc2eulydBknVrWsKXKUICgLqiIpJxQcecOqAKBKqqqaJIFTGjMTkWEGESmRghFjCOpC9AH6H9mA4U4+FdDkAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(lowResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x160364F8308>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(biCubicImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x16036FEC708>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(superResImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}