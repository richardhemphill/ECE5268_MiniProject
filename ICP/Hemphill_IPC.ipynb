{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e",
   "display_name": "Python 3.7.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2ee6990e829ee75785e20acf53b05f75aefa7ec77d0c7f557db63932b894e5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2x Single-Image Super-Resolution on Grayscale Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Assignment:** Individual Class Project<br>\n",
    "**Author:** Richard Hemphill<br>\n",
    "**ID:** 903877709<br>\n",
    "**Class:** ECE5268 Theory of Neural Networks<br>\n",
    "**Instructor:** Dr. Georgios C. Anagnostopoulos<br>\n",
    "**Description:** Using small-sized grayscale images, construct a CNN-based architecture that will downscale (magnify) the images by a factor of 2.<br>\n",
    "**Emphasis:** Describe the concept of single-image super-resolution, describe the architecture in sufficient detail and show indicative training and post-training results.<br>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**References:**\n",
    "* https://www.kaggle.com/spaceengineer1/alexonly-greyscale\n",
    "* https://www.kaggle.com/c/two-sigma-financial-news/discussion/83593\n",
    "* https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os.path\n",
    "import random\n",
    "import shutil\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RANDRANGE_STOP=10000\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SET_OWNER = 'spaceengineer1'\n",
    "IMAGE_SET_FILE = 'alexonly-greyscale'\n",
    "ZIP_EXTENSION = 'zip'\n",
    "IMAGE_EXTENSION = 'jpg'\n",
    "PROCESSED_IMAGE_FOLDER ='dataSet'\n",
    "TRAIN_FOLDER = 'train'\n",
    "TEST_FOLDER = 'test'\n",
    "RESCALE_FACTOR = 1./255\n",
    "VALIDATION_SPLIT = 0.2\n",
    "CHANNELS = 1\n",
    "ORIG_IMG_SIZE = 64\n",
    "UPSCALE_FACTOR = 2\n",
    "LOW_RES_IMG_SIZE = int(ORIG_IMG_SIZE/UPSCALE_FACTOR)"
   ]
  },
  {
   "source": [
    "## Prepocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raw image set\n",
    "def DownloadImageSet(imageSetOwner = IMAGE_SET_OWNER, imageSetFile = IMAGE_SET_FILE):\n",
    "    zipFile = '{}.{}'.format(imageSetFile, ZIP_EXTENSION)\n",
    "    if not os.path.isfile(zipFile):\n",
    "        # connect to the Kaggle Database and download dataset\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_download_files('{}/{}'.format(imageSetOwner, imageSetFile))\n",
    "    # extract the dataset\n",
    "    zf = ZipFile(zipFile)\n",
    "    topDir = ''.join({item.split('/')[0] for item in zf.namelist()})\n",
    "    if not os.path.isdir(topDir):\n",
    "        zf.extractall() \n",
    "        zf.close()\n",
    "\n",
    "    trainDirPre = os.path.join(topDir,TEST_FOLDER)\n",
    "    if os.path.isdir(trainDirPre):\n",
    "        shutil.move(trainDirPre, '.')\n",
    "        \n",
    "    return topDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Images\n",
    "imgFolder = DownloadImageSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageNorm(image):\n",
    "    image = image/255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shrink(image):\n",
    "    return tf.image.resize(image,[LOW_RES_IMG_SIZE,LOW_RES_IMG_SIZE],method='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 804 files belonging to 1 classes.\nUsing 644 files for training.\n"
     ]
    }
   ],
   "source": [
    "trainSet = image_dataset_from_directory(\n",
    "    directory=imgFolder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(ORIG_IMG_SIZE,ORIG_IMG_SIZE),\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='training',\n",
    "    seed=random.randrange(RANDRANGE_STOP),\n",
    "    label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=64x64 at 0x2C9133DAAC8>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "for batch in trainSet.take(1):\n",
    "    display(array_to_img(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = trainSet.map(ImageNorm)\n",
    "trainSet = trainSet.map(lambda x: (Shrink(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 804 files belonging to 1 classes.\nUsing 160 files for validation.\n"
     ]
    }
   ],
   "source": [
    "valSet = image_dataset_from_directory(\n",
    "    directory=imgFolder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='validation',\n",
    "    seed=random.randrange(RANDRANGE_STOP),\n",
    "    label_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "valSet = valSet.map(ImageNorm)\n",
    "valSet = valSet.map(lambda x: (Shrink(x),x))"
   ]
  },
  {
   "source": [
    "## Create Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperResolution():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=CHANNELS * LOW_RES_IMG_SIZE^2, kernel_size=9, activation='relu', padding='same'))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=1, activation='relu', padding='same'))\n",
    "    model.add(keras.layers.Conv2D(filters=CHANNELS * ORIG_IMG_SIZE^2, kernel_size=5, activation='relu', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = SuperResolution()\n",
    "srOpt = keras.optimizers.SGD(learning_rate=0.001)\n",
    "srLossFn = keras.losses.MeanSquaredError()\n",
    "sr.compile(optimizer=srOpt, loss=srLossFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:10250 squared_difference\n        \"SquaredDifference\", x=x, y=y, name=name)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:592 _create_op_internal\n        compute_device)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3536 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2016 __init__\n        control_input_ops, op_def)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 32 and 64 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_8/conv2d_26/Relu, IteratorGetNext:1)' with input shapes: [?,32,32,66], [?,64,64,3].\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-88c159937d87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:10250 squared_difference\n        \"SquaredDifference\", x=x, y=y, name=name)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:592 _create_op_internal\n        compute_device)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3536 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2016 __init__\n        control_input_ops, op_def)\n    C:\\Users\\richa\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 32 and 64 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_8/conv2d_26/Relu, IteratorGetNext:1)' with input shapes: [?,32,32,66], [?,64,64,3].\n"
     ]
    }
   ],
   "source": [
    "sr.fit(trainSet, epochs=EPOCHS, validation_data=valSet, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}