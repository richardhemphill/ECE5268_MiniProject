{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "682f7833ba8e905d5acff324393f9b2a5e85cb3ab0887fadf22e785eb301dcc5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Predicting MPG with SDC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Author:** Richard Hemphill<br>\n",
    "**ID:** 903877709<br>\n",
    "**Class:** ECE5268 Theory of Neural Networks<br>\n",
    "**Instructor:** Dr. Georgios C. Anagnostopoulos<br>\n",
    "**Description:** Utilize characteristics from various cars to predict miles-per-gallon fuel consumption.  The prediction equation is determined using Stocastic Gradient Descent minimization method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "DATASET_FILE = 'autompg_dataset.csv'\n",
    "NUMBER_FOR_TRAINING = 200\n",
    "NUMBER_FOR_VALIDATION = 100\n",
    "OUTPUT_FEATURE='mpg'\n",
    "INPUT_FEATURES=['horsepower', 'weight']\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np                  # matrix manipulation\n",
    "import random                       # shuffle data\n",
    "import matplotlib.pyplot as plt     # surface plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "# Create Augmented Design Matrix\n",
    "def AugmentedDesignMatrix(dataSet, features):\n",
    "    # Create the design matrix.\n",
    "    adm = dataSet[features[0]]\n",
    "    for feature in features[1:]:\n",
    "        adm = np.column_stack((adm,dataSet[feature]))\n",
    "     # Augment the design matrix to accomodate the bias term.\n",
    "    adm = np.column_stack((adm,np.ones(len(adm))))\n",
    "    return adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error\n",
    "def MSE(actual, predicted):\n",
    "    return np.square(np.subtract(actual, predicted)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictionEquation(y, xs, w):\n",
    "    eq = '{} = '.format(y)\n",
    "    wfmat = lambda i: ('+' if i > 0 else '') + '{:0.6}'.format(i)\n",
    "    for idx, x in enumerate(xs):\n",
    "        eq = eq + '{}*{}'.format(wfmat(w[idx]), x)\n",
    "    eq = eq + wfmat(w[-1])\n",
    "    return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data file\n",
    "csvFile = open(DATASET_FILE, 'r')\n",
    "dataSet = np.genfromtxt(csvFile, delimiter=',', names=True, case_sensitive=True)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data randomly so that training will not use same sets every time.\n",
    "random.shuffle(dataSet)"
   ]
  },
  {
   "source": [
    "# Split the data set into groups for training, validation and test.\n",
    "trainData = dataSet[:NUMBER_FOR_TRAINING]\n",
    "valData = dataSet[NUMBER_FOR_TRAINING+1:NUMBER_FOR_TRAINING+NUMBER_FOR_VALIDATION]\n",
    "testData = dataSet[NUMBER_FOR_TRAINING+NUMBER_FOR_VALIDATION+1:]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 165,
   "outputs": []
  },
  {
   "source": [
    "## Part (a): Batch Size 1\n",
    "tbd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch(0)\niteration(0)\nsample(0)\n[1.300e+02 3.504e+03 1.000e+00]\n-18.0\nsample(1)\n[1.300e+02 3.504e+03 1.000e+00]\n-18.0\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "maxLearningRate = 0.1\n",
    "decay = 1\n",
    "batchSize = 2\n",
    "iterations = 1#round(len(trainData)/batchSize)\n",
    "Wa = np.zeros(len(INPUT_FEATURES)+1)\n",
    "for e in range(EPOCHS):\n",
    "    print('epoch({})'.format(e))\n",
    "    for i in range(iterations):\n",
    "        print('iteration({})'.format(i))\n",
    "        batch = trainData[batchSize*i:batchSize*(i+1)]\n",
    "        Y = batch[OUTPUT_FEATURE]\n",
    "        X = AugmentedDesignMatrix(dataSet=batch,features=INPUT_FEATURES)\n",
    "        dE = None\n",
    "        for s in range(batchSize):\n",
    "            print('sample({})'.format(s))\n",
    "            Ys = Y[s]\n",
    "            Xs = X[s]\n",
    "            print(Xs.T)\n",
    "            print(np.dot(Xs,Wa)-Ys)\n",
    "            #dE = dE + np.dot(Xs.T,(np.dot(Xs,Wa)-Ys))\n",
    "        #g = dE/batchSize\n",
    "        #learningRate = maxLearningRate/(1+(decay*i))\n",
    "        #d = -learningRate * g\n",
    "        #dW = d\n",
    "        #Wa = Wa + dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(PredictionEquation(y=OUTPUT_FEATURE, xs=INPUT_FEATURES, w=Wa))"
   ]
  }
 ]
}